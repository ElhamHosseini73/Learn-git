{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNd9CVXfODp2lk9S53fTc+z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElhamHosseini73/Learn-git/blob/main/tensorflow_recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX_1B1SiLZxh"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.15.0 tensorflow-recommenders"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EpGE1T2aX5-u"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "import tensorflow_datasets as tfds\n",
        "from typing import Dict, Text\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "1atQtuUELyTx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MovieLens dataset\n",
        "ratings = tfds.load('movielens/100k-ratings', split=\"train\")"
      ],
      "metadata": {
        "id": "Q_V7fHDXMrmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data to extract only the user_id and movie_id\n",
        "def preprocess_data(data):\n",
        "    return data.map(lambda x: {\n",
        "        \"user_id\": x[\"user_id\"],\n",
        "        \"movie_id\": x[\"movie_id\"],\n",
        "    })\n",
        "\n",
        "preprocessed_data = preprocess_data(ratings)\n",
        "train = preprocessed_data.take(80_000)  # Training split\n",
        "test = preprocessed_data.skip(80_000).take(20_000)  # Testing split\n"
      ],
      "metadata": {
        "id": "ysVLH177Nb8R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract unique user_ids and movie_ids into a list\n",
        "user_ids = np.unique([x['user_id'].numpy() for x in train])\n",
        "movie_ids = np.unique([x['movie_id'].numpy() for x in train])"
      ],
      "metadata": {
        "id": "4wN6vzcROa_M"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User embedding model\n",
        "user_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.StringLookup(vocabulary=user_ids, mask_token=None),\n",
        "    tf.keras.layers.Embedding(input_dim=len(user_ids) + 1, output_dim=32)\n",
        "])\n",
        "\n",
        "# Movie embedding model\n",
        "movie_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.StringLookup(vocabulary=movie_ids, mask_token=None),\n",
        "    tf.keras.layers.Embedding(input_dim=len(movie_ids) + 1, output_dim=32)\n",
        "])"
      ],
      "metadata": {
        "id": "4k1Q0KpDSm2Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MovielandsModel(tfrs.Model):\n",
        "    def __init__(self, user_model, movie_model, movie_ids):\n",
        "        super().__init__()\n",
        "        self.user_model = user_model\n",
        "        self.movie_model = movie_model\n",
        "\n",
        "        # Convert movie_ids (numpy array) to a TensorFlow Dataset\n",
        "        movie_dataset = tf.data.Dataset.from_tensor_slices(movie_ids)\n",
        "\n",
        "        # Create a FactorizedTopK layer with candidates as batched movie embeddings\n",
        "        self.task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=movie_dataset.batch(128).map(lambda x: movie_model(x))\n",
        "        ))\n",
        "\n",
        "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "        # Get user and movie embeddings\n",
        "        user_embeddings = self.user_model(features[\"user_id\"])\n",
        "        movie_embeddings = self.movie_model(features[\"movie_id\"])\n",
        "\n",
        "        # Return the loss from the task (retrieval)\n",
        "        return self.task(user_embeddings, movie_embeddings)\n",
        "\n",
        "# Initialize the model\n",
        "model = MovielandsModel(user_model=user_model, movie_model=movie_model, movie_ids=movie_ids)\n"
      ],
      "metadata": {
        "id": "yQDWfQzTUho_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
      ],
      "metadata": {
        "id": "z6m7ccpAPP9l"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train.batch(4096), epochs=3)"
      ],
      "metadata": {
        "id": "LGH_JlqBbOeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test.batch(4096), return_dict=True)"
      ],
      "metadata": {
        "id": "xhVz2oUCbZgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert movie_ids (which is a numpy array) into a TensorFlow dataset\n",
        "movie_dataset = tf.data.Dataset.from_tensor_slices(movie_ids)\n",
        "\n",
        "# Build the retrieval index using the BruteForce layer\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
        "\n",
        "# Index the movie embeddings\n",
        "index.index_from_dataset(\n",
        "    movie_dataset.batch(100).map(lambda movie_id: (movie_id, model.movie_model(movie_id)))\n",
        ")\n",
        "\n",
        "# Get top 5 movie recommendations for a specific user\n",
        "_, movies = index(tf.constant([\"user_1\"]), k=5)\n",
        "\n",
        "# Print the recommendations\n",
        "print(f\"Top 5 movie recommendations for user_1: {movies.numpy()}\")\n"
      ],
      "metadata": {
        "id": "GXX6CF34dsq3",
        "outputId": "9d57ef61-fa27-4d4a-b1f8-da67e3f25970",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 movie recommendations for user_1: [[b'273' b'544' b'129' b'952' b'293']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.save(\"movieland_retrieval_model\")\n"
      ],
      "metadata": {
        "id": "C-zfM2pXd9Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the dataset\n",
        "for example in train.take(1):\n",
        "    print(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRX-WhcdM9Uq",
        "outputId": "fe082a7e-afe2-4cd6-e2f5-b50a915ad541"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'138'>, 'movie_id': <tf.Tensor: shape=(), dtype=string, numpy=b'357'>}\n"
          ]
        }
      ]
    }
  ]
}